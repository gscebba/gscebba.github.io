<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Gaetano Scebba </title> <meta name="author" content="Gaetano Scebba"> <meta name="description" content="Publications in reversed chronological order."> <meta name="keywords" content="gaetano scebba, data scientist, biomedical engineering, machine learning, digital health"> <meta property="og:site_name" content="Gaetano Scebba"> <meta property="og:type" content="website"> <meta property="og:title" content="Gaetano Scebba | publications"> <meta property="og:url" content="https://gaetanoscebba.com/publications/"> <meta property="og:description" content="Publications in reversed chronological order."> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="publications"> <meta name="twitter:description" content="Publications in reversed chronological order."> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Gaetano Scebba"
        },
        "url": "https://gaetanoscebba.com/publications/",
        "@type": "WebSite",
        "description": "Publications in reversed chronological order.",
        "headline": "publications",
        
        "sameAs": ["https://scholar.google.com/citations?user=rnwEwCoAAAAJ","https://github.com/gscebba","https://www.linkedin.com/in/gaetano-scebba-338a3b76"],
        
        "name": "Gaetano Scebba",
        "@context": "https://schema.org"
    }
  </script> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.svg?v=e9220150c1a7493a331612b754b8f15f"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gaetanoscebba.com/publications/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Gaetano</span> Scebba </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">Publications in reversed chronological order.</p> </header> <article> <script src="/assets/js/bibsearch.js?v=1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">JCIM</abbr> </div> <div id="unique_jcim_2024" class="col-sm-8"> <div class="title">UNIQUE: A Framework for Uncertainty Quantification Benchmarking</div> <div class="author"> Jessica Lanini, Minh Tam Davide Huynh, <em>Gaetano Scebba</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Nadine Schneider, Raquel Rodríguez-Pérez' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Journal of Chemical Information and Modeling</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1021/acs.jcim.4c01578" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://pubs.acs.org/doi/10.1021/acs.jcim.4c01578" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Novartis/UNIQUE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Machine learning models have become key in decision-making for many disciplines, including drug discovery and medicinal chemistry. Therefore, uncertainty quantification (UQ) in ML predictions has gained importance in recent years. Many investigations have focused on developing methodologies that provide accurate uncertainty estimates for ML-based predictions. Unfortunately, there is no UQ strategy that consistently provides robust estimates about model’s applicability on new samples. Depending on the dataset, prediction task, and algorithm, accurate uncertainty estimations might be unfeasible to obtain. The UNIQUE (UNcertaInty QUantification bEnchmarking) framework is introduced to facilitate a comparison of UQ strategies in ML-based predictions. This Python library unifies the benchmarking of multiple UQ metrics, including the calculation of nonstandard UQ metrics (combining information from the dataset and model), and provides a comprehensive evaluation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">unique_jcim_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{UNIQUE}: A Framework for Uncertainty Quantification Benchmarking}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lanini, Jessica and Huynh, Minh Tam Davide and Scebba, Gaetano and Schneider, Nadine and Rodr{\'i}guez-P{\'e}rez, Raquel}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Chemical Information and Modeling}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{64}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{22}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8379--8386}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1021/acs.jcim.4c01578}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAIC</abbr> </div> <div id="aaic_23" class="col-sm-8"> <div class="title">Motor-cognitive dual tasking in the clinical setting: a sensitive measure of functional impairment in early Alzheimer’s disease</div> <div class="author"> Anna-Katrine Brem, <em>Gaetano Scebba</em>, Jelena Curcic, and <span class="more-authors" title="click to view 17 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '17 more authors' ? 'Marjin Muurling, Casper Boer, Neva Coello, Alankar Atreya, Pauline Conde, Holger Frohlich, Margarita Grammatikopoulou, Chris Hinds, Ioulietta Lazarou, Manuel Lentzen, Vaibhav A Narayan, Rouba Kozak, Spiros Nikolopoulos, Srinivasan Vairavan, Pieter Jelle Visser, Gayle Wittenberg, Dag Aarsland' : '17 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">17 more authors</span> </div> <div class="periodical"> <em>In Alzheimer’s Association International Conference 2023</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://alz.confex.com/alz/2023/meetingapp.cgi/Paper/71137" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Gait is a complex everyday activity that depends upon supraspinal activity and a host of cognitive functions such as attention and executive functions. As cognition declines in neurodegenerative diseases, the interaction and competition for neuronal resources during motor-cognitive dual-tasking (e.g., walking while talking) might be a sensitive measure of subtle functional impairments in early Alzheimer’s disease (AD). Here, we aim to identify gait deficits due to neuronal competition across the AD spectrum.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">aaic_23</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Motor-cognitive dual tasking in the clinical setting: a sensitive measure of functional impairment in early {Alzheimer's} disease}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brem, Anna-Katrine and Scebba, Gaetano and Curcic, Jelena and Muurling, Marjin and de Boer, Casper and Coello, Neva and Atreya, Alankar and Conde, Pauline and Frohlich, Holger and Grammatikopoulou, Margarita and Hinds, Chris and Lazarou, Ioulietta and Lentzen, Manuel and Narayan, Vaibhav A and Kozak, Rouba and Nikolopoulos, Spiros and Vairavan, Srinivasan and Visser, Pieter Jelle and Wittenberg, Gayle and Aarsland, Dag}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Alzheimer's Association International Conference 2023}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Patent</abbr> </div> <div id="patent_eth" class="col-sm-8"> <div class="title">A system for recording a high-quality wound image and for real-time image quality assessment</div> <div class="author"> Jia Zhang, <em>Gaetano Scebba</em>, and Walter Karlen </div> <div class="periodical"> 2022 </div> <div class="periodical"> European Patent EP4092620A1 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://worldwide.espacenet.com/patent/search?q=pn%3DEP4092620A1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The patent describes a system for recording high-quality wound images and real-time image quality assessment. The system consists of a computerized mobile device with a camera, processor, non-transitory storage medium, and display, and a reference marker for color and sharpness evaluation. The mobile device’s non-transitory storage medium contains a computer program that, when executed on the processor, causes the camera to record an image of a wound and reference marker and evaluates the image’s sharpness and displays feedback information on the display.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">patent_eth</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A system for recording a high-quality wound image and for real-time image quality assessment}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Jia and Scebba, Gaetano and Karlen, Walter}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{European Patent EP4092620A1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IMU</abbr> </div> <div id="wou_imu" class="col-sm-8"> <div class="title">Detect-and-Segment: A Deep Learning Approach to Automate Wound Image Segmentation</div> <div class="author"> <em>Gaetano Scebba</em>, Jia Zhang, Sabrina Catanzaro, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Carina Mihai, Oliver Distler, Martin Berli, Walter Karlen' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>Informatics in Medicine Unlocked</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.imu.2022.100884" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S2352914822000375" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Chronic wounds significantly impact quality of life. They can rapidly deteriorate and require close monitoring of healing progress. Image-based wound analysis is a way of objectively assessing the wound status by quantifying important features that are related to healing. However, high heterogeneity of the wound types and imaging conditions challenge the robust segmentation of wound images. We present Detect-and-Segment (DS), a deep learning approach to produce wound segmentation maps with high generalization capabilities. In our approach, dedicated deep neural networks detected the wound position, isolated the wound from the perturbing background, and computed a wound segmentation map. We tested this approach on a diabetic foot ulcers data set and compared it to a segmentation method based on the full image. The Matthews correlation coefficient (MCC) improved from 0.29 (full image) to 0.85 (DS) on the diabetic foot ulcer data set. When the DS was tested on the independent data sets, the mean MCC increased from 0.17 to 0.85. Furthermore, the DS enabled the training of segmentation models with up to 90% less training data without impacting the segmentation performance. The proposed DS approach is a step towards automating wound analysis and reducing efforts to manage chronic wounds.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wou_imu</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Detect-and-Segment: A Deep Learning Approach to Automate Wound Image Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Scebba, Gaetano and Zhang, Jia and Catanzaro, Sabrina and Mihai, Carina and Distler, Oliver and Berli, Martin and Karlen, Walter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Informatics in Medicine Unlocked}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100884}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2352-9148}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.imu.2022.100884}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">JMIR</abbr> </div> <div id="JMIR2021_scleroderma" class="col-sm-8"> <div class="title">Wound Image Quality From a Mobile Health Tool for Home-Based Chronic Wound Management With Real-Time Quality Feedback: Randomized Feasibility Study</div> <div class="author"> Jia Zhang, Carina Mihai, Laura Tüshaus, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Gaetano Scebba, Oliver Distler, Walter Karlen' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>JMIR mHealth and uHealth</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.research-collection.ethz.ch/handle/20.500.11850/500386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://mhealth.jmir.org/2021/7/e26149/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Background: Travel to clinics for chronic wound management is burdensome to patients. Remote assessment and management of wounds using mobile and telehealth approaches can reduce this burden and improve patient outcomes. An essential step in wound documentation is the capture of wound images, but poor image quality can have a negative influence on the reliability of the assessment. Objective: Our goal was to develop a mobile health (mHealth) tool for the remote self-assessment of digital ulcers (DUs) in patients with systemic sclerosis (SSc). Methods: We developed an mHealth tool composed of a wound imaging and management app, a custom color reference sticker, and a smartphone holder. Results: A total of 21 patients were enrolled, of which 15 patients were included in the image quality analysis. Conclusions: We developed an mHealth tool that enables patients with SSc to acquire good-quality DU images and demonstrated that it is feasible to deploy such an app in this patient group.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">JMIR2021_scleroderma</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wound Image Quality From a Mobile Health Tool for Home-Based Chronic Wound Management With Real-Time Quality Feedback: Randomized Feasibility Study}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Jia and Mihai, Carina and T{\"u}shaus, Laura and Scebba, Gaetano and Distler, Oliver and Karlen, Walter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{JMIR mHealth and uHealth}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e26149}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{JMIR Publications Inc., Toronto, Canada}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMBC</abbr> </div> <div id="EMBC2020_rrCovariance" class="col-sm-8"> <div class="title">Covariance Intersection to Improve the Robustness of the Photoplethysmogram Derived Respiratory Rate</div> <div class="author"> Jia Zhang, <em>Gaetano Scebba</em>, and Walter Karlen </div> <div class="periodical"> <em>In 2020 42nd Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2004.09934" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Respiratory rate (RR) can be estimated from the photoplethysmogram (PPG) recorded by optical sensors in wearable devices. The fusion of estimates from different PPG features has lead to an increase in accuracy, but also reduced the numbers of available final estimates due to discarding of unreliable data. We propose a novel, tunable fusion algorithm using covariance intersection to estimate the RR from PPG (CIF). The algorithm is adaptive to the number of available feature estimates and takes each estimates’ trustworthiness into account. In a benchmarking experiment using the CapnoBase dataset with reference RR from capnography, we compared the CIF against the state-of-the-art Smart Fusion (SF) algorithm. The median root mean square error was 1.4 breaths/min for the CIF and 1.8 breaths/min for the SF. The CIF significantly increased the retention rate distribution of all recordings from 0.46 to 0.90 (p &lt; 0.001). The agreement with the reference RR was high with a Pearson’s correlation coefficient of 0.94, a bias of 0.3 breaths/min, and limits of agreement of -4.6 and 5.2 breaths/min. In addition, the algorithm was computationally efficient. Therefore, CIF could contribute to a more robust RR estimation from wearable PPG recordings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">EMBC2020_rrCovariance</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Covariance Intersection to Improve the Robustness of the Photoplethysmogram Derived Respiratory Rate}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Jia and Scebba, Gaetano and Karlen, Walter}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2020 42nd Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE TBME</abbr> </div> <div id="ieeeTBME20_RRfusion" class="col-sm-8"> <div class="title">Multispectral Video Fusion for Non-contact Monitoring of Respiratory Rate and Apnea</div> <div class="author"> <em>Gaetano Scebba</em>, Giulia Da Poian, and Walter Karlen </div> <div class="periodical"> <em>IEEE Transactions on Biomedical Engineering</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://arxiv.org/abs/2004.09834" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://ieeexplore.ieee.org/document/9091089" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Continuous monitoring of respiratory activity is desirable in many clinical applications to detect respiratory events. Non-contact monitoring of respiration can be achieved with near- and far-infrared spectrum cameras. However, current technologies are not sufficiently robust to be used in clinical applications. For example, they fail to estimate an accurate respiratory rate (RR) during apnea. We present a novel algorithm based on multispectral data fusion that aims at estimating RR also during apnea. The algorithm independently addresses the RR estimation and apnea detection tasks. Respiratory information is extracted from multiple sources and fed into an RR estimator and an apnea detector whose results are fused into a final respiratory activity estimation. We evaluated the system retrospectively using data from 30 healthy adults who performed diverse controlled breathing tasks while lying supine in a dark room and reproduced central and obstructive apneic events. Combining multiple respiratory information from multispectral cameras improved the root mean square error (RMSE) accuracy of the RR estimation from up to 4.64 monospectral data down to 1.60 breaths/min. The median F1 scores for classifying obstructive (0.75 to 0.86) and central apnea (0.75 to 0.93) also improved. Furthermore, the independent consideration of apnea detection led to a more robust system (RMSE of 4.44 vs. 7.96 breaths/min). Our findings may represent a step towards the use of cameras for vital sign monitoring in medical applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ieeeTBME20_RRfusion</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multispectral Video Fusion for Non-contact Monitoring of Respiratory Rate and Apnea}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Scebba, Gaetano and Da Poian, Giulia and Karlen, Walter}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Biomedical Engineering}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{68}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{350--359}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMBC</abbr> </div> <div id="EMBC2018_multispectralROI" class="col-sm-8"> <div class="title">Multispectral camera fusion increases robustness of ROI detection for biosignal estimation with nearables in real-world scenarios</div> <div class="author"> <em>Gaetano Scebba</em>, Laura Tüshaus, and Walter Karlen </div> <div class="periodical"> <em>In 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.research-collection.ethz.ch/handle/20.500.11850/500386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://doi.org/10.1109/EMBC.2018.8513501" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Thermal cameras enable non-contact estimation of the respiratory rate (RR). Accurate estimation of RR is highly dependent on the reliable detection of the region of interest (ROI), especially when using cameras with low pixel resolution. We present a novel approach for the automatic detection of the human nose ROI, based on facial landmark detection from an RGB camera that is fused with the thermal image after tracking. We evaluated the detection rate and spatial accuracy of the novel algorithm on recordings obtained from 16 subjects under challenging detection scenarios. Results show a high detection rate (median: 100%, 5th-95th percentile: 92%-100%) and very good spatial accuracy with an average root mean square error of 2 pixels in the detected ROI center when compared to manual labeling. Therefore, the implementation of a multispectral camera fusion algorithm is a valid strategy to improve the reliability of non-contact RR estimation with nearable devices featuring thermal cameras.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">EMBC2018_multispectralROI</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multispectral camera fusion increases robustness of {ROI} detection for biosignal estimation with nearables in real-world scenarios}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Scebba, Gaetano and T{\"u}shaus, Laura and Karlen, Walter}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5672--5675}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CinC</abbr> </div> <div id="cinc2017_BeatByBeat" class="col-sm-8"> <div class="title">Beat by Beat: Classifying Cardiac Arrhythmias with Recurrent Neural Networks</div> <div class="author"> Patrick Schwab, <em>Gaetano Scebba</em>, Jia Zhang, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Marco Delai, Walter Karlen' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Computing in Cardiology</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/1710.06319.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>With tens of thousands of electrocardiogram (ECG) records processed by mobile cardiac event recorders every day, heart rhythm classification algorithms are an important tool for the continuous monitoring of patients at risk. We utilise an annotated dataset of 12,186 single-lead ECG recordings to build a diverse ensemble of recurrent neural networks (RNNs) that is able to distinguish between normal sinus rhythms, atrial fibrillation, other types of arrhythmia and signals that are too noisy to interpret. In order to ease learning over the temporal dimension, we introduce a novel task formulation that harnesses the natural segmentation of ECG signals into heartbeats to drastically reduce the number of time steps per sequence. Additionally, we extend our RNNs with an attention mechanism that enables us to reason about which heartbeats our RNNs focus on to make their decisions. Through the use of attention, our model maintains a high degree of interpretability, while also achieving state-of-the-art classification performance with an average F1 score of 0.79 on an unseen test set (n=3658).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cinc2017_BeatByBeat</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Beat by Beat: Classifying Cardiac Arrhythmias with Recurrent Neural Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schwab, Patrick and Scebba, Gaetano and Zhang, Jia and Delai, Marco and Karlen, Walter}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Computing in Cardiology}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMBC</abbr> </div> <div id="EMBC2017_ppgROI" class="col-sm-8"> <div class="title">Improving ROI detection in photoplethysmographic imaging with thermal cameras</div> <div class="author"> <em>Gaetano Scebba</em>, Jelena Dragas, Suyi Hu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Walter Karlen' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1109/EMBC.2017.8037803" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Photoplethismographic imaging (PPGi) enables the estimation of heart rate without body contact by analyzing the temporal skin color changes from video recordings. Motion artifacts and atypical facial characteristics cause poor signals and currently limit the applicability of PPGi. We have developed a novel algorithm for locating cheek and forehead region of interests (ROI) with the aim to improve PPGi during challenging situations. The proposed approach is based on the fusion of RGB and far-infrared (FIR) video streams where FIR ROI is used as fall-back when RGB alone fails. We validated and compared the algorithm against the detection based on single sources, using videos from 8 subjects with distinctively different face characteristics. The subject performed three scenarios with incremental motion artifact content (head at rest, intensive head movements, speaking). The results showed that combining the two imaging sources increased the detection rate of cheeks from 75% (RGB) to 92% (RGB+FIR) in the challenging intensive head movement scenario. This work demonstrated that FIR imaging is complementary to simple RGB imaging and when combined, adds robustness to the detection of ROI in PPGi applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">EMBC2017_ppgROI</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Improving {ROI} detection in photoplethysmographic imaging with thermal cameras}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Scebba, Gaetano and Dragas, Jelena and Hu, Suyi and Karlen, Walter}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4285--4288}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Gaetano Scebba. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>